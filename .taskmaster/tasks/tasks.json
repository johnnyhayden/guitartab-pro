{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Project Repository",
        "description": "Initialize the project repository with version control and basic project structure.",
        "details": "Create a new Git repository for the project. Set up the basic directory structure for frontend and backend components. Initialize package managers for frontend (npm/yarn) and backend (pipenv/virtualenv).",
        "testStrategy": "Verify that the repository is accessible and the initial structure is correctly set up by cloning and running basic commands.",
        "priority": "medium",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Initialize Git repository and remote",
            "description": "Create the project root, initialize a Git repository with main branch, add baseline files (.gitignore, README, LICENSE), create/connect a remote repository, make the initial commit, and push.",
            "dependencies": [],
            "details": "- Create project directory and initialize Git: mkdir <project-name> && cd <project-name> && git init -b main\n- Create baseline files:\n  - README.md: include project name, summary, and high-level structure goals\n  - LICENSE: choose MIT or appropriate license\n  - .gitignore: include common Node, Python, and OS ignores (e.g., node_modules/, dist/, build/, .venv/, __pycache__/, .DS_Store, .env, .pytest_cache/)\n  - .gitattributes: text=auto eol=lf (optional)\n- Create and connect remote repo:\n  - Using GitHub CLI: gh repo create <org-or-user>/<repo> --public --source=. --remote=origin --push\n  - Or create manually on hosting provider, then: git remote add origin git@github.com:<org-or-user>/<repo>.git\n- First commit and push: git add . && git commit -m \"chore: initial repository setup\" && git push -u origin main\n- Configure repository settings (optional): default branch main, protect main branch, require PR reviews.",
            "status": "done",
            "testStrategy": "Run git remote -v to confirm remote connection. Visit the remote host to verify the repository exists and initial files are present. Optionally git clone <repo-url> ../tmp-clone and verify contents.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T21:55:32.307Z"
          },
          {
            "id": 2,
            "title": "Create base project directory structure",
            "description": "Establish a clear directory layout for frontend, backend, and project support assets to scaffold subsequent work.",
            "dependencies": [],
            "details": "- Create directories: mkdir -p frontend src placeholder if needed; mkdir -p backend; mkdir -p docs; mkdir -p scripts; mkdir -p .github/workflows\n- Add placeholder files so empty dirs are tracked: touch frontend/README.md backend/README.md docs/README.md scripts/README.md\n- Add an .editorconfig at repo root to enforce consistency (e.g., root=true; indent_size=2; end_of_line=lf; insert_final_newline=true)\n- Update README.md with a short directory layout section and contribution/getting started notes\n- Commit: git add . && git commit -m \"chore: scaffold base project structure\" && git push",
            "status": "done",
            "testStrategy": "List files (e.g., tree -a -L 2 or ls -la) and verify directories exist and are tracked. Confirm README includes the structure overview.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T21:57:26.904Z"
          },
          {
            "id": 3,
            "title": "Initialize frontend package manager (npm) and baseline configs",
            "description": "Set up Node.js tooling for the frontend with npm, add minimal lint/format configuration, and create placeholder source structure.",
            "dependencies": [],
            "details": "- Ensure Node.js LTS is available (e.g., nvm install --lts && nvm use; echo \"$(node -v)\" > frontend/.nvmrc)\n- Initialize npm in frontend: cd frontend && npm init -y\n- Create src and entry file: mkdir -p src && echo \"console.log('frontend initialized');\" > src/index.js\n- Add lint/format tooling: npm install -D eslint prettier eslint-config-prettier eslint-plugin-import\n- Create .eslintrc.json:\n  { \"env\": {\"browser\": true, \"es2021\": true, \"node\": true}, \"extends\": [\"eslint:recommended\", \"prettier\"], \"parserOptions\": {\"ecmaVersion\": 2021, \"sourceType\": \"module\"}, \"rules\": {} }\n- Create .prettierrc: {}\n- Add npm scripts to package.json: \"scripts\": { \"lint\": \"eslint \\\"src/**/*.js\\\"\", \"format\": \"prettier --write \\\"src/**/*.{js,json,md}\\\"\", \"format:check\": \"prettier --check \\\"src/**/*.{js,json,md}\\\"\" }\n- Commit: git add . && git commit -m \"chore(frontend): initialize npm and lint/format configs\" && git push\n- Note: If using Yarn instead of npm, run yarn init -y and replace npm commands accordingly.",
            "status": "done",
            "testStrategy": "From frontend/: run npm install to ensure dependencies install; run npm run lint and npm run format:check to confirm tooling works. Confirm src/index.js exists and no lint errors are reported.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:36:01.821Z"
          },
          {
            "id": 4,
            "title": "Initialize backend Python environment (pipenv) and baseline structure",
            "description": "Set up Python virtual environment with pipenv for the backend and create a minimal backend scaffolding.",
            "dependencies": [],
            "details": "- Ensure Python 3.11+ is available (e.g., pyenv install 3.11.x && pyenv local 3.11.x in backend/ if using pyenv)\n- Initialize pipenv in backend: cd backend && pipenv --python 3.11\n- Optionally add dev tools: pipenv install --dev black flake8 isort\n- Create basic structure: mkdir -p src/app && touch src/app/__init__.py && echo \"print('backend initialized')\" > src/app/main.py\n- Create config files (optional but recommended):\n  - .flake8 with basic rules (e.g., [flake8] max-line-length = 100; extend-ignore = E203,W503)\n  - pyproject.toml for Black/isort configuration (e.g., [tool.black] line-length = 100; [tool.isort] profile = \"black\")\n  - .env.example with placeholders (e.g., FLASK_ENV=development; DATABASE_URL=postgresql://user:pass@localhost:5432/db)\n- Add basic Makefile in backend/ with recipes: install (pipenv install --dev), fmt (pipenv run black . && pipenv run isort .), lint (pipenv run flake8)\n- Commit: git add . && git commit -m \"chore(backend): initialize pipenv and baseline structure\" && git push",
            "status": "done",
            "testStrategy": "From backend/: run pipenv run python src/app/main.py and verify output. If dev tools installed, run pipenv run black --version and pipenv run flake8 to confirm they execute.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:39:19.178Z"
          },
          {
            "id": 5,
            "title": "Configure pre-commit hooks and CI, then validate by cloning",
            "description": "Add repository-wide pre-commit hooks for basic hygiene and a CI workflow to verify installs for frontend and backend. Validate setup by cloning and running basic commands.",
            "dependencies": [],
            "details": "- Pre-commit setup (root):\n  - If using pipenv, install: cd backend && pipenv install --dev pre-commit && cd ..\n  - Create .pre-commit-config.yaml at repo root with hooks: trailing-whitespace, end-of-file-fixer, check-yaml, check-merge-conflict, mixed-line-ending; plus language-specific (optional): black, isort (repo: psf/black, PyCQA/isort), flake8; prettier (repo: pre-commit/mirrors-prettier, target frontend files)\n  - Install hooks: pre-commit install (run via pipenv: pipenv run pre-commit install from backend/ or use a global pre-commit install)\n- CI setup (GitHub Actions): create .github/workflows/ci.yml with two jobs on push/pull_request:\n  - frontend job: actions/setup-node@v4 (lts), working-directory: frontend, run: npm ci || npm install, then npm run lint and npm run format:check\n  - backend job: actions/setup-python@v5 (3.11), install pipenv, working-directory: backend, run: pipenv --python 3.11 && pipenv install --dev, then optional lint (pipenv run flake8)\n- Update README with CI status badge and local development instructions (frontend and backend basic commands)\n- Final validation by cloning fresh:\n  - In a separate directory: git clone <repo-url> fresh-clone && cd fresh-clone\n  - Run frontend check: cd frontend && npm install && npm run lint && cd ..\n  - Run backend check: cd backend && pipenv install --dev && pipenv run python src/app/main.py && cd ..\n  - Run pre-commit across repo: (from backend/) pipenv run pre-commit run --all-files",
            "status": "done",
            "testStrategy": "Open a pull request to trigger CI and confirm both jobs pass. Locally, verify pre-commit blocks malformed changes. Validate a fresh clone can install and run the basic commands without errors.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:42:28.341Z"
          },
          {
            "id": 6,
            "title": "Configure .gitignore, .gitattributes, and .editorconfig",
            "description": "Add standard ignore rules and text/line-ending normalization to ensure a clean, cross-platform repository.",
            "dependencies": [],
            "details": "Create a root-level .gitignore covering Python (.venv, venv, __pycache__, *.pyc, .pytest_cache, .mypy_cache, coverage/), Node (node_modules/, dist/, build/, .next/, coverage/), IDE/OS (.DS_Store, .idea/, .vscode/), env files (.env, .env.*), logs (*.log), and lockfiles as needed; add .gitattributes to enforce text eol=lf by default, mark common binaries (e.g., *.png, *.jpg, *.pdf) as binary, and set linguist settings if needed; add .editorconfig to standardize indentation (2 spaces for JS/TS/JSON/YAML, 4 spaces for Python), UTF-8, LF line endings, final newline, and trimming trailing whitespace.",
            "status": "done",
            "testStrategy": "Run `git check-ignore -v` on representative files to confirm ignore coverage; stage files with `git add -A` and verify no unwanted artifacts are tracked; confirm line endings with `git ls-files --eol`; ensure editors pick up .editorconfig by saving sample files.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:42:47.863Z"
          },
          {
            "id": 7,
            "title": "Initialize repository documentation and policies",
            "description": "Create foundational repo docs and community health files to guide contributors and clarify licensing.",
            "dependencies": [
              "1.6"
            ],
            "details": "Add README.md with project overview, architecture layout (frontend/backend), quick start, and development scripts; choose and add LICENSE (e.g., MIT) and note year/owner; add CONTRIBUTING.md (branching strategy, Conventional Commits, code style, PR process), CODE_OF_CONDUCT.md, and SECURITY.md (vulnerability reporting); create CHANGELOG.md with Keep a Changelog format; add .github/ISSUE_TEMPLATE (bug_report.yml, feature_request.yml) and .github/PULL_REQUEST_TEMPLATE.md; include status badges placeholders for CI and coverage.",
            "status": "done",
            "testStrategy": "Preview README locally to verify sections render; run a markdown linter (e.g., markdownlint) to ensure formatting; check that GitHub recognizes the license and templates by attempting to open a new issue/PR; verify links with a link checker.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:42:54.330Z"
          },
          {
            "id": 8,
            "title": "Create environment templates and bootstrap scripts",
            "description": "Provide reproducible setup via env templates and scripted bootstrapping for frontend and backend.",
            "dependencies": [
              "1.6"
            ],
            "details": "Add backend/.env.example (e.g., DATABASE_URL, JWT_SECRET, FLASK_ENV) and frontend/.env.example (e.g., VITE_API_BASE_URL or NEXT_PUBLIC_API_BASE_URL); add .nvmrc (Node 20.x) and .python-version (e.g., 3.11) for tooling consistency; create Makefile (or Taskfile) with targets: setup, backend.install, frontend.install, lint, format, test, run, clean; add scripts/bootstrap.sh (POSIX) and scripts/bootstrap.ps1 (Windows) to install Python env (virtualenv/pipenv), Node deps (npm ci or yarn install), and pre-commit; ensure package.json scripts exist for lint/test/build in frontend; commit lockfiles (Pipfile.lock/poetry.lock; package-lock.json/yarn.lock) if applicable.",
            "status": "done",
            "testStrategy": "From a fresh clone, run the bootstrap or `make setup` and verify: Python env created, dependencies installed, Node deps installed, and pre-commit installed; copy .env.example to .env for both apps and confirm commands `make lint` and `make test` run without errors; confirm Node and Python versions via the files are honored.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:42:54.359Z"
          },
          {
            "id": 9,
            "title": "Set up code quality and git hooks (pre-commit, linters, formatters, secret scan)",
            "description": "Configure automated formatting, linting, type checks, and secret scanning enforced via git hooks.",
            "dependencies": [
              "1.6",
              "1.8"
            ],
            "details": "Add .pre-commit-config.yaml with hooks: black, isort, ruff or flake8, trailing-whitespace, end-of-file-fixer, detect-secrets; configure pyproject.toml for black/isort/ruff settings; for frontend, add ESLint (.eslintrc) and Prettier (.prettierrc) with compatible rules; add npm scripts `lint`, `format`, and `lint:fix`; integrate commit message linting using @commitlint/config-conventional with a commit-msg hook (via pre-commit or Husky if needed); document usage in README; ensure CI can run the same checks.",
            "status": "done",
            "testStrategy": "Run `pre-commit run --all-files` to validate hooks; introduce intentionally misformatted files and ensure hooks fail and auto-fix where applicable; attempt a commit with a non-conforming message and confirm it is blocked; run `npm run lint` and Python linters to verify no errors.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:42:54.375Z"
          },
          {
            "id": 10,
            "title": "Configure CI workflows (GitHub Actions) for linting and tests",
            "description": "Add CI pipelines for backend and frontend to run on pushes/PRs with caching, artifacts, and coverage.",
            "dependencies": [
              "1.8",
              "1.9"
            ],
            "details": "Create .github/workflows/backend.yml to set up Python (3.11), install deps (cache pip), run pre-commit, unit tests, and upload coverage (e.g., to Codecov) on push/pull_request; create frontend.yml to set up Node (20.x), install deps with npm ci (cache), run lint, tests, and build; define concurrency groups and required checks for main branch; add status badges to README; optionally add a workflow to validate PR titles against Conventional Commits.",
            "status": "done",
            "testStrategy": "Open a draft PR to trigger workflows and verify all jobs pass; inspect workflow logs for cache hits and coverage upload; test a failing lint or test to ensure CI blocks merges; enable branch protection requiring the CI checks to pass before merging.",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:42:54.391Z"
          }
        ],
        "updatedAt": "2025-09-26T22:42:54.391Z"
      },
      {
        "id": 2,
        "title": "Database Schema Design",
        "description": "Design and implement the PostgreSQL database schema for users, songs, and songlists.",
        "details": "Create tables for Users, Songs, Songlists, Songlist_Songs, and User_Preferences. Define primary keys, foreign keys, and necessary indexes. Use SQLAlchemy for ORM mapping in the backend.",
        "testStrategy": "Run database migration scripts and verify the schema using database inspection tools. Ensure all tables and relationships are correctly established.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Requirements, ERD, and Naming Conventions",
            "description": "Capture detailed requirements, model entities/relations, and define schema/naming conventions.",
            "dependencies": [],
            "details": "Scope: Users, Songs, Songlists, Songlist_Songs (junction with position), User_Preferences (1:1 with Users).\nKey attributes:\n- users: id (uuid), email (citext), display_name (text), created_at, updated_at\n- songs: id (uuid), title (text), artist (text), album (text), duration_seconds (int), metadata (jsonb), created_at, updated_at\n- songlists: id (uuid), owner_id (uuid), name (text), description (text), is_public (bool), created_at, updated_at\n- songlist_songs: id (uuid), songlist_id (uuid), song_id (uuid), position (int), added_at (timestamptz)\n- user_preferences: user_id (uuid pk), prefs (jsonb), updated_at\nConventions:\n- snake_case table/column names; singular table names: users, songs, songlists, songlist_songs, user_preferences\n- Constraint/index naming: pk_<table>, fk_<table>__<col>__<reftable>, uq_<table>__<cols>, ix_<table>__<cols>, ck_<table>__<name>\n- Timestamps: timestamptz with default now(); app-managed onupdate for updated_at\nDeliverables: ERD diagram (PNG/DBML), conventions doc, attribute/type matrix.\nAcceptance criteria (data integrity): ERD reflects exact relationships (1:N users->songlists; M:N songlists<->songs via junction; 1:1 users->user_preferences). All required attributes and nullability documented; naming conventions approved and referenced by migrations/ORM.",
            "status": "done",
            "testStrategy": "",
            "updatedAt": "2025-09-26T22:46:19.543Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Alembic Base Setup and Migration Strategy",
            "description": "Initialize Alembic, configure metadata naming conventions, and define migration workflow.",
            "dependencies": [
              "2.1"
            ],
            "details": "Tasks:\n- alembic init, configure env.py to load SQLAlchemy Base.metadata with naming_convention\n- Enable required extensions via migration: CREATE EXTENSION IF NOT EXISTS pgcrypto; CREATE EXTENSION IF NOT EXISTS citext;\n- Strategy: one base schema revision (tables), followed by constraints/indexes if split is desired; always include downgrade paths\n- Autogenerate enabled; manual review required; migration IDs use message slugs\n- Envs: online/offline support; version_table schema default 'public'\nAcceptance criteria: alembic upgrade head and downgrade base succeed on fresh DB; naming_convention enforced; extensions created idempotently; CI job runs migrations without prompts.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:49:09.777Z"
          },
          {
            "id": 3,
            "title": "Create Core Tables (DDL)",
            "description": "Author DDL migrations for Users, Songs, Songlists, Songlist_Songs, and User_Preferences.",
            "dependencies": [
              "2.1",
              "2.2"
            ],
            "details": "DDL (representative):\n- users: CREATE TABLE users (id uuid PRIMARY KEY DEFAULT gen_random_uuid(), email citext NOT NULL, display_name text, created_at timestamptz NOT NULL DEFAULT now(), updated_at timestamptz NOT NULL DEFAULT now());\n- songs: CREATE TABLE songs (id uuid PRIMARY KEY DEFAULT gen_random_uuid(), title text NOT NULL, artist text NOT NULL, album text, duration_seconds integer NOT NULL DEFAULT 0, metadata jsonb NOT NULL DEFAULT '{}'::jsonb, created_at timestamptz NOT NULL DEFAULT now(), updated_at timestamptz NOT NULL DEFAULT now());\n- songlists: CREATE TABLE songlists (id uuid PRIMARY KEY DEFAULT gen_random_uuid(), owner_id uuid NOT NULL, name text NOT NULL, description text, is_public boolean NOT NULL DEFAULT false, created_at timestamptz NOT NULL DEFAULT now(), updated_at timestamptz NOT NULL DEFAULT now());\n- songlist_songs: CREATE TABLE songlist_songs (id uuid PRIMARY KEY DEFAULT gen_random_uuid(), songlist_id uuid NOT NULL, song_id uuid NOT NULL, position integer NOT NULL, added_at timestamptz NOT NULL DEFAULT now());\n- user_preferences: CREATE TABLE user_preferences (user_id uuid PRIMARY KEY, prefs jsonb NOT NULL DEFAULT '{}'::jsonb, updated_at timestamptz NOT NULL DEFAULT now());\nAcceptance criteria (data integrity): All tables exist with columns and defaults as specified; no orphaned required columns left nullable; migration is reversible.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:51:38.757Z"
          },
          {
            "id": 4,
            "title": "Constraints, Foreign Keys, and Cascade Rules",
            "description": "Define FKs, uniqueness, and check constraints with appropriate ON DELETE behavior.",
            "dependencies": [
              "2.3"
            ],
            "details": "Constraints:\n- users: UNIQUE (email)\n- songs: CHECK (duration_seconds >= 0)\n- songlists: FK owner_id -> users(id) ON DELETE CASCADE\n- songlist_songs: FK songlist_id -> songlists(id) ON DELETE CASCADE; FK song_id -> songs(id) ON DELETE CASCADE; CHECK (position >= 1); UNIQUE (songlist_id, song_id); UNIQUE (songlist_id, position)\n- user_preferences: FK user_id -> users(id) ON DELETE CASCADE; enforce 1:1 via PK\nOptional email format check: CHECK (email ~* '^[^@]+@[^@]+\\.[^@]+$')\nAcceptance criteria (data integrity): Inserting duplicates for unique columns fails; invalid positions or negative durations fail; deleting a user cascades to songlists and preferences; deleting songlists removes junction rows; deleting a song removes its junction rows; downgrade removes constraints cleanly.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:51:38.792Z"
          },
          {
            "id": 5,
            "title": "Indexes (Unique, Search, and Query-Driven)",
            "description": "Create indexes to support uniqueness, filtering, and search patterns.",
            "dependencies": [
              "2.3",
              "2.4"
            ],
            "details": "Indexes:\n- users: CREATE UNIQUE INDEX uq_users__email ON users(email);\n- songs: CREATE INDEX ix_songs__title_artist ON songs (title, artist); CREATE INDEX ix_songs__search ON songs USING GIN (to_tsvector('simple', coalesce(title,'') || ' ' || coalesce(artist,'')));\n- songlists: CREATE INDEX ix_songlists__owner_public ON songlists (owner_id, is_public);\n- songlist_songs: CREATE INDEX ix_songlist_songs__song_id ON songlist_songs (song_id); (uniques defined in constraints)\nAcceptance criteria (performance): EXPLAIN on typical queries uses indexes (btree or gin); uniqueness enforced by index; no duplicate overlapping indexes; downgrade drops indexes.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:51:38.807Z"
          },
          {
            "id": 6,
            "title": "SQLAlchemy Models and Relationships (with Type Hints)",
            "description": "Implement ORM models for all tables with relationships and typing.",
            "dependencies": [
              "2.3",
              "2.4",
              "2.5"
            ],
            "details": "Models (sketch):\n- Use Declarative with typing: from sqlalchemy.orm import Mapped, mapped_column, relationship\n- class User: id: Mapped[UUID]; email: Mapped[str]; display_name: Mapped[Optional[str]]; songlists: Mapped[list[Songlist]] = relationship(back_populates='owner', cascade='all, delete-orphan'); preferences: Mapped['UserPreferences'] = relationship(uselist=False, back_populates='user', cascade='all, delete-orphan')\n- class Song: id, title, artist, album, duration_seconds, metadata; songlists: Mapped[list['SonglistSong']] = relationship(back_populates='song', cascade='all, delete-orphan')\n- class Songlist: id, owner_id, name, ...; owner: relationship('User', back_populates='songlists'); items: Mapped[list['SonglistSong']] = relationship(back_populates='songlist', cascade='all, delete-orphan', order_by='SonglistSong.position')\n- class SonglistSong (association object): id, songlist_id, song_id, position, added_at; song: relationship('Song', back_populates='songlists'); songlist: relationship('Songlist', back_populates='items')\n- class UserPreferences: user_id PK, prefs (dict[str, Any]), updated_at; user: relationship('User', back_populates='preferences')\n- Configure __tablename__, indexes via __table_args__ to match naming_convention\nAcceptance criteria: ORM reflects DDL (columns, nullability, constraints). Relationship cascades align with FKs. Type hints pass mypy basic checks. SQLAlchemy can create and query relationships (add items with positions) without violating constraints.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:51:38.822Z"
          },
          {
            "id": 7,
            "title": "Seed/Sample Data and Fixtures",
            "description": "Provide seed script and test fixtures with realistic sample data.",
            "dependencies": [
              "2.3",
              "2.6"
            ],
            "details": "Deliverables:\n- scripts/seed.py: inserts N users, M songs, K songlists; populates songlist_songs with unique (songlist_id, song_id) and sequential position; creates default user_preferences per user\n- Optional Alembic data revision for minimal bootstrap records (e.g., admin user)\n- Pytest fixtures: db_engine, db_session, seed_data factory for integration tests\nAcceptance criteria: Seed runs idempotently (clears or upserts as appropriate) in non-prod. All FKs and unique constraints satisfied. Basic queries return expected counts (e.g., each songlist has 5+ songs).",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:51:38.839Z"
          },
          {
            "id": 8,
            "title": "Validation and Migration Tests (Upgrade/Downgrade) + Performance Smoke",
            "description": "Write tests to validate schema integrity, migrations, and basic performance.",
            "dependencies": [
              "2.2",
              "2.3",
              "2.4",
              "2.5",
              "2.6",
              "2.7"
            ],
            "details": "Tests:\n- Migration cycle: upgrade -> seed -> downgrade -> upgrade; verify no residual objects\n- Integrity: uniques (users.email), checks (position>=1, duration>=0), FKs/cascades (deleting user cascades songlists/preferences; deleting songlist removes junction rows)\n- ORM: create/read/update/delete via models, relationship loading and ordering by position\n- Search index smoke: EXPLAIN analyze on title/artist search shows GIN index usage\n- Performance: On sample dataset (e.g., 10k songs), typical queries under 50ms on dev machine; no sequential scans for indexed filters\nAcceptance criteria: All tests pass in CI. Upgrade and downgrade succeed. EXPLAIN plans show index usage. Data integrity enforced by constraints and ORM prevents invalid state.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:51:38.859Z"
          }
        ],
        "updatedAt": "2025-09-26T22:51:38.859Z"
      },
      {
        "id": 3,
        "title": "User Authentication System",
        "description": "Implement JWT-based user authentication with secure password handling.",
        "details": "Use Flask-JWT-Extended for JWT handling and bcrypt for password hashing. Implement registration, login, and password reset endpoints. Store user credentials securely in the database.",
        "testStrategy": "Write unit tests for authentication endpoints. Verify JWT tokens are issued and validated correctly. Test password hashing and storage security.",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Security decisions: JWT lifetimes, rotation, and storage strategy",
            "description": "Define and document the core security configuration for JWT usage and token storage.",
            "dependencies": [],
            "details": "Decide and document:\n- JWT algorithm HS256 with a 256-bit SECRET_KEY from environment; include iss, sub, iat, nbf, exp, jti, and roles claims; 30s clock skew leeway.\n- Access token TTL: 15 minutes; Refresh token TTL: 7 days.\n- Refresh token rotation on every refresh; enable reuse detection and compromise response (revoke all existing refresh tokens for the user, require re-auth).\n- Token storage and transport: issue tokens in JSON response using Authorization: Bearer for clients; document guidance for web clients to prefer HttpOnly, Secure cookies if needed (server can optionally set cookies behind a flag).\n- Server-side revocation store: DB table for jti with indexes (user_id, jti, token_type, expires_at, revoked_at, reason); implement Flask-JWT-Extended callbacks to check revocation.\n- CORS and cookie settings: SameSite=Lax/Strict when cookies enabled, Secure and HttpOnly; restrict allowed origins.\nAcceptance Criteria:\n- A SECURITY.md and config module with the above decisions exist; all values configurable via env vars.\n- Tokens include jti and exp and are rejected when expired or revoked.\n- Storage strategy and rotation behavior are unambiguously specified for implementation and testing.",
            "status": "done",
            "testStrategy": "",
            "updatedAt": "2025-09-26T22:55:26.967Z",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Password policy and bcrypt configuration",
            "description": "Define password requirements and configure bcrypt hashing parameters.",
            "dependencies": [
              "3.1"
            ],
            "details": "Implement:\n- Password policy: min length 12; require uppercase, lowercase, digit, and special character; disallow email reuse; reject common passwords (use a lightweight top-10k list or zxcvbn score >= 3 if available).\n- Bcrypt configuration: bcrypt.gensalt(rounds=12) configurable via env; use constant-time comparisons; include per-hash salt from bcrypt.\n- Secure storage: store only bcrypt hashes; never store plaintext; ensure unique index on user email.\nAcceptance Criteria:\n- Creating a user stores a bcrypt hash (starts with $2) with configured cost.\n- Weak or common passwords are rejected with clear error messages.\n- Verification uses constant-time compare and passes unit tests.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:26.988Z"
          },
          {
            "id": 3,
            "title": "Registration endpoint with email uniqueness and validation",
            "description": "Implement /auth/register with input validation and secure password handling.",
            "dependencies": [
              "3.1",
              "3.2"
            ],
            "details": "Implement POST /auth/register:\n- Request: { email, password, display_name? } with schema validation; normalize and validate email format.\n- Enforce email uniqueness (conflict returns 409) and rate-limit registrations per IP.\n- Hash password with bcrypt; store created_at/updated_at; default role=user.\n- Response: 201 with minimal user info (id, email, created_at); do not auto-issue tokens.\nAcceptance Criteria:\n- Duplicate emails return 409; invalid input returns 400 with field errors.\n- DB stores only bcrypt hashes; no plaintext secrets in logs.\n- Endpoint covered by unit tests.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.002Z"
          },
          {
            "id": 4,
            "title": "Login endpoint with throttling/rate limiting and token issuance",
            "description": "Implement /auth/login with credential verification, rate limits, and JWT issuance.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3"
            ],
            "details": "Implement POST /auth/login:\n- Request: { email, password }.\n- Rate limits: e.g., 5/min per IP and 10/hour per account; exponential backoff on repeated failures.\n- On success: issue access and refresh tokens per security decisions; include roles claim; return JSON { access_token, refresh_token, expires_in }.\n- On failure: return 401 with generic message; use constant-time checks; log suspicious activity.\nAcceptance Criteria:\n- Tokens contain jti, exp, sub, and roles; validate via Flask-JWT-Extended.\n- Rate limits enforced and tested; successful login returns 200 with both tokens.\n- No sensitive error leakage (e.g., user enumeration).",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.015Z"
          },
          {
            "id": 5,
            "title": "Refresh, logout, and token revocation strategy implementation",
            "description": "Implement /auth/refresh, /auth/logout, and revocation checks with refresh rotation and reuse detection.",
            "dependencies": [
              "3.1",
              "3.4"
            ],
            "details": "Implement:\n- POST /auth/refresh: requires valid refresh token; rotate refresh token; persist new refresh jti; revoke old one; detect reuse and mark session compromised (revoke all tokens for user) and respond 401.\n- POST /auth/logout: revoke current access and refresh tokens; optionally provide /auth/logout-all to revoke all user tokens.\n- Revocation callbacks: integrate with Flask-JWT-Extended to check jti against revocation store for both access and refresh tokens.\n- Index revocation table for performance and TTL cleanup job.\nAcceptance Criteria:\n- Old refresh tokens cannot be reused after rotation (tested).\n- After logout, access token is rejected on protected endpoints; reuse detection triggers compromise workflow.\n- Revocation checks run on every authenticated request.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.029Z"
          },
          {
            "id": 6,
            "title": "Password reset flow (email adapter) and change password endpoint",
            "description": "Implement secure password reset via emailed token and authenticated password change.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3"
            ],
            "details": "Implement:\n- POST /auth/request-password-reset: accept email; respond 200 regardless of existence; generate single-use, time-bound reset token (store hashed token with user_id, expires_at, used_at); send via email adapter interface; rate-limit requests.\n- POST /auth/reset-password: verify token and expiration; enforce password policy; update bcrypt hash; invalidate all active tokens for the user; delete/mark used reset tokens.\n- POST /auth/change-password (auth required): verify current password; enforce policy; update hash; revoke all tokens (require re-login).\nAcceptance Criteria:\n- No account enumeration via responses or timing.\n- Reset tokens are single-use, short-lived (e.g., 1 hour), and stored hashed; all user tokens revoked after password change/reset.\n- Flow covered by tests, including token expiry and replay rejection.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.044Z"
          },
          {
            "id": 7,
            "title": "Role and claims scaffolding for future authorization",
            "description": "Add role storage and include claims in JWTs, plus basic decorators for role checks.",
            "dependencies": [
              "3.1",
              "3.3"
            ],
            "details": "Implement:\n- Extend user model to include role (e.g., user, admin) and optional custom claims field.\n- Inject roles claim into JWTs at issuance; add helper to refresh claims.\n- Provide @roles_required(['admin']) decorator and sample protected endpoint for demonstration.\nAcceptance Criteria:\n- Issued tokens contain roles claim; protected sample endpoint returns 403 for insufficient role and 200 for admin in tests.\n- Minimal migration and backfill strategy documented.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.442Z"
          },
          {
            "id": 8,
            "title": "Tests: unit, integration, and threat-model checks",
            "description": "Comprehensive tests covering endpoints, token lifecycle, storage security, and abuse cases.",
            "dependencies": [
              "3.1",
              "3.2",
              "3.3",
              "3.4",
              "3.5",
              "3.6",
              "3.7"
            ],
            "details": "Implement tests with pytest and Flask test client:\n- Unit tests: validators, bcrypt hashing/verification, JWT claim contents, revocation lookup.\n- Integration tests: register/login/refresh/logout, rotation and reuse detection, password reset and change flows, role-protected routes, rate-limiting behavior (with time mocking), token expiry (freezegun).\n- Security checks: ensure no plaintext password storage, env-based secrets required, tokens rejected when expired/revoked, deny \"none\" algorithm.\n- Threat model checklist: enumerate key risks (token theft, fixation, replay, brute-force) and mitigation verification.\nAcceptance Criteria:\n- All tests pass in CI; coverage >= 85% for auth modules.\n- Explicit tests verify token issuance/validation and secure storage properties.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.462Z"
          },
          {
            "id": 9,
            "title": "Documentation and client usage examples",
            "description": "Produce API docs, examples, and guidance for secure client token handling.",
            "dependencies": [
              "3.3",
              "3.4",
              "3.5",
              "3.6",
              "3.7"
            ],
            "details": "Deliverables:\n- OpenAPI/Swagger docs for /auth/register, /auth/login, /auth/refresh, /auth/logout, /auth/request-password-reset, /auth/reset-password, /auth/change-password.\n- Example flows (curl and Python) for registration, login, refresh rotation, logout-all, password reset, and role-protected access.\n- Token lifecycle diagram and guidance on storage (Authorization header vs HttpOnly cookies), error handling patterns, and rate-limit backoff.\n- Postman collection and README updates.\nAcceptance Criteria:\n- A developer can complete full auth flows using examples.\n- Docs clearly state token issuance/validation expectations and secure storage recommendations.",
            "status": "done",
            "testStrategy": "",
            "parentId": "undefined",
            "updatedAt": "2025-09-26T22:55:27.482Z"
          }
        ],
        "updatedAt": "2025-09-26T22:55:27.482Z"
      },
      {
        "id": 4,
        "title": "Basic Flask API Setup",
        "description": "Set up the core REST API endpoints for user and song management.",
        "details": "Create a Flask application with endpoints for CRUD operations on users and songs. Implement basic error handling and input validation.",
        "testStrategy": "Use Postman or similar tools to test API endpoints. Write integration tests to ensure endpoints function as expected.",
        "priority": "medium",
        "dependencies": [
          "3"
        ],
        "status": "in-progress",
        "subtasks": [
          {
            "id": 1,
            "title": "Application factory and environment-based configuration",
            "description": "Implement create_app with env-specific config and register core extensions.",
            "dependencies": [],
            "details": "Scope:\n- Add app factory: create_app(env=None) selecting DevelopmentConfig, TestingConfig, ProductionConfig via APP_ENV/FLASK_ENV.\n- Configure: SECRET_KEY, SQLALCHEMY_DATABASE_URI, SQLALCHEMY_TRACK_MODIFICATIONS=False, JWT_SECRET_KEY (from Task 3), JSON_SORT_KEYS=False, PROPAGATE_EXCEPTIONS=True, default pagination limits.\n- Initialize extensions: SQLAlchemy, Marshmallow, Flask-Migrate, CORS, logging (structured with request-id), and optionally JWT (do not enforce auth yet).\n- Set API base prefix '/api/v1'; add simple '/api/health' endpoint.\nDeliverables:\n- config.py with config classes; app/__init__.py with create_app; extensions.py for initialized instances; .env.example.\nAcceptance Criteria:\n- create_app returns a Flask app with correct env config (TestingConfig uses in-memory SQLite and TESTING=True).\n- App boots and GET /api/health returns 200 JSON {\"status\":\"ok\"}.\n- Extensions are registered without runtime errors; URL prefixing works for '/api/v1/*'.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Blueprints for users and songs with routing conventions",
            "description": "Define versioned blueprints and RESTful routes for users and songs.",
            "dependencies": [
              "4.1"
            ],
            "details": "Scope:\n- Create blueprints: users_bp (prefix '/api/v1/users'), songs_bp (prefix '/api/v1/songs').\n- Define CRUD routes: GET '' (list), POST '' (create), GET '<int:id>' (retrieve), PUT/PATCH '<int:id>' (update), DELETE '<int:id>' (delete).\n- Establish route names (e.g., users.list_users) and consistent ID param naming ('user_id', 'song_id').\n- Register blueprints in create_app; provide temporary stub handlers returning JSON placeholders until CRUD is implemented in Subtask 4.7.\nDeliverables:\n- app/users/routes.py and app/songs/routes.py with route stubs and registration wiring.\n- Routing conventions doc (versioning, nouns, no verbs, plural resources).\nAcceptance Criteria:\n- URL map includes all listed routes under '/api/v1'.\n- Temporary stub responses return 200 JSON {\"status\":\"stub\"} for list/get and 501 for unimplemented mutations (to be finalized in Subtask 4.7).",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Global error handlers with RFC 7807 problem+json responses",
            "description": "Centralize error handling and standardize JSON error contract.",
            "dependencies": [
              "4.1"
            ],
            "details": "Scope:\n- Implement error handlers for: HTTPException (use code), Marshmallow ValidationError (422), SQLAlchemy IntegrityError (409), NotFound (404), generic Exception (500).\n- Response format: application/problem+json with fields: type (URI), title, status, detail, instance (request path), correlation_id, and errors (field-level issues map) when applicable.\n- Add request ID middleware (X-Request-ID; generate if missing) and include in logs and error responses.\n- Map unknown routes to 404 problem+json.\nDeliverables:\n- app/errors.py with handler registrations; middleware to attach correlation_id; documentation of error contract with examples.\nAcceptance Criteria:\n- Any raised HTTPException returns application/problem+json with correct status and headers.\n- Validation errors produce 422 with errors map; IntegrityError returns 409 with conflict detail.\n- Responses include correlation_id and instance; content-type is application/problem+json.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Input validation schemas and response models",
            "description": "Create Marshmallow schemas for users/songs and decorators to validate/serialize.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3"
            ],
            "details": "Scope:\n- Schemas: UserCreate(email, username, password), UserUpdate(optional fields), UserOut(id, email, username, created_at); SongCreate(title, artist, tuning?, difficulty?), SongUpdate, SongOut(id, title, artist, created_at).\n- Constraints: email format, username [a-z0-9_]{3,30}, password length>=8, title required; coerce/strip strings.\n- List envelope schema: { items: [...], meta: { page, per_page, total, pages, sort, order } }.\n- Implement decorators/helpers: validate_request(schema) -> parsed data on g; serialize_response(schema or envelope) -> consistent output.\n- Ensure sensitive fields (password) never serialized in responses.\nDeliverables:\n- app/schemas/user.py, app/schemas/song.py; app/utils/validation.py decorators; schema docs.\nAcceptance Criteria:\n- Invalid payloads yield 422 problem+json with field-level errors; valid payloads pass data to handlers.\n- Successful responses conform to output schemas; no password or sensitive data in any response.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Pagination and sorting utilities",
            "description": "Implement reusable helpers for page/per_page and sorting with validation.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4"
            ],
            "details": "Scope:\n- Helper parse_pagination(args, defaults): supports page>=1, per_page [1..100], defaults from config.\n- Sorting: parse_sort(args, allowed_fields) supporting 'sort' and 'order' or a '-field' syntax; validate allowed fields per resource.\n- SQLAlchemy integration: apply_pagination(query) returning items and total; build Link header (first, prev, next, last) and meta object.\n- Validation errors surface via problem+json (422) with clear messages; unknown sort fields rejected.\nDeliverables:\n- app/utils/pagination.py with parsing, SQLAlchemy helpers, and header/meta builders; usage examples in docstrings.\nAcceptance Criteria:\n- GET list endpoints can pass page/per_page/sort/order to helpers and receive consistent meta and Link headers.\n- Invalid pagination/sort inputs return 422 problem+json with errors map; defaults apply when params omitted.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "OpenAPI/Swagger documentation with CI validation",
            "description": "Generate and serve OpenAPI spec and validate it in CI.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4",
              "4.5"
            ],
            "details": "Scope:\n- Define OpenAPI 3.0 spec (openapi.yaml/json) using apispec + Marshmallow schemas; include servers, tags (Users, Songs), components/schemas, and shared Problem+JSON error schema.\n- Annotate routes with operationIds, parameters (pagination/sort), request bodies, and standardized responses (200, 201 with Location, 204, 400/422/404/409 via problem+json).\n- Serve /api/openapi.json and Swagger UI at /api/docs.\n- CI: add job to validate spec with openapi-spec-validator and Spectral lint; fail build on errors.\nDeliverables:\n- docs/openapi.yaml; app/docs.py serving spec and docs; CI workflow config (e.g., .github/workflows/openapi-validate.yml).\nAcceptance Criteria:\n- GET /api/openapi.json returns a valid spec; Swagger UI loads with no console errors.\n- CI validation passes on main and PRs; error responses documented consistently across endpoints.",
            "status": "pending",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Test harness (pytest fixtures, client) and minimal CRUD skeletons",
            "description": "Add pytest setup and implement minimal working CRUD for users and songs.",
            "dependencies": [
              "4.1",
              "4.2",
              "4.3",
              "4.4",
              "4.5",
              "4.6"
            ],
            "details": "Scope:\n- Pytest setup: conftest.py with app(), client(), db() fixtures using TestingConfig; factory for sample users/songs; transactional test isolation.\n- Implement CRUD handlers using SQLAlchemy models (from Task 2) + schemas + pagination utilities:\n  - Users: POST create (201, Location), GET list (200 + meta + Link), GET by id (200/404), PATCH/PUT update (200/404), DELETE (204/404). Exclude password from responses.\n  - Songs: same pattern; define allowed sort fields.\n- Negative cases: validation 422, conflict 409 on unique constraints, not found 404, bad pagination/sort 422; all errors follow problem+json contract.\n- Optional: protect write operations with JWT (Task 3) behind a feature flag; tests can run without auth.\n- Coverage and run scripts.\nDeliverables:\n- Implemented route handlers replacing stubs; tests under tests/api/test_users.py and tests/api/test_songs.py; coverage config (>=80%).\nAcceptance Criteria:\n- All tests pass locally and in CI; coverage >=80% for app package.\n- Endpoints behavior:\n  - Create returns 201 with Location header pointing to resource URI and body matching *Out schema.\n  - List returns 200 with items[] and meta; Link header present when applicable.\n  - Get returns 200 with resource or 404 problem+json if missing.\n  - Update returns 200 with updated resource; partial updates accepted for PATCH.\n  - Delete returns 204 with empty body.\n- Error contract: application/problem+json with fields {type,title,status,detail,instance,correlation_id,errors?} for all error responses.",
            "status": "pending",
            "testStrategy": ""
          }
        ],
        "updatedAt": "2025-09-26T22:55:36.049Z"
      },
      {
        "id": 5,
        "title": "Frontend Framework Initialization",
        "description": "Initialize the frontend using a modern JavaScript framework (Vue.js or React).",
        "details": "Set up a new project using Vue CLI or Create React App. Configure routing and state management (Vuex or Redux). Implement a basic responsive layout.",
        "testStrategy": "Verify the frontend builds and runs without errors. Test routing and state management through browser testing.",
        "priority": "medium",
        "dependencies": [
          "1"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Song CRUD Operations",
        "description": "Implement create, read, update, and delete operations for songs in the backend.",
        "details": "Develop API endpoints for song CRUD operations. Ensure proper validation and error handling. Integrate with the database using SQLAlchemy.",
        "testStrategy": "Write unit and integration tests for each CRUD operation. Verify database changes through direct inspection.",
        "priority": "medium",
        "dependencies": [
          "4"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Basic Search Functionality",
        "description": "Implement simple text-based search for songs by title and artist.",
        "details": "Use PostgreSQL full-text search capabilities to implement search functionality. Create API endpoints to handle search queries.",
        "testStrategy": "Test search functionality with various queries. Validate results against expected outcomes.",
        "priority": "medium",
        "dependencies": [
          "6"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Add PostgreSQL full-text search vector and GIN index for Songs",
            "description": "Create a tsvector search column for the Songs table combining title and artist, and index it to enable fast full-text search.",
            "dependencies": [],
            "details": "Implementation approach (Alembic migration + SQLAlchemy):\n1) Create an Alembic migration that:\n   - Ensures required extensions exist (optional but recommended):\n     - op.execute(\"CREATE EXTENSION IF NOT EXISTS pg_trgm\")  // optional, not strictly needed for FTS\n     - op.execute(\"CREATE EXTENSION IF NOT EXISTS unaccent\")  // optional if you want diacritic-insensitive search\n   - Adds a STORED generated column (PostgreSQL 12+):\n     op.execute(\"\"\"\n       ALTER TABLE songs\n       ADD COLUMN search_vector tsvector GENERATED ALWAYS AS (\n         setweight(to_tsvector('simple', coalesce(title, '')), 'A') ||\n         setweight(to_tsvector('simple', coalesce(artist, '')), 'B')\n       ) STORED\n     \"\"\");\n     // Use 'simple' config to avoid stemming of names; switch to 'english' if desired.\n   - Creates a GIN index on search_vector:\n     op.execute(\"CREATE INDEX IF NOT EXISTS idx_songs_search_vector ON songs USING GIN (search_vector)\");\n   - If STORED generated columns are not available in your environment, fall back to:\n     - Add a plain tsvector column search_vector\n     - Backfill: UPDATE songs SET search_vector = setweight(to_tsvector('simple', coalesce(title, '')), 'A') || setweight(to_tsvector('simple', coalesce(artist, '')), 'B');\n     - Add trigger to keep it updated:\n       op.execute(\"CREATE FUNCTION songs_search_vector_update() RETURNS trigger LANGUAGE plpgsql AS $$ BEGIN NEW.search_vector := setweight(to_tsvector('simple', coalesce(NEW.title, '')), 'A') || setweight(to_tsvector('simple', coalesce(NEW.artist, '')), 'B'); RETURN NEW; END $$;\");\n       op.execute(\"CREATE TRIGGER trg_songs_search_vector BEFORE INSERT OR UPDATE OF title, artist ON songs FOR EACH ROW EXECUTE FUNCTION songs_search_vector_update();\");\n     - Create the same GIN index as above.\n2) Update the SQLAlchemy model (if needed) to include the search_vector column as a deferred/read-only column for query use; it doesnt need to be exposed via API.\n3) Run migration and verify the index exists.",
            "status": "pending",
            "testStrategy": "Post-migration verification: SELECT to_regclass('public.idx_songs_search_vector') should not be NULL. Seed a few songs, run an EXPLAIN on a sample FTS query (WHERE search_vector @@ websearch_to_tsquery('simple', 'beatles')) and confirm the GIN index is used.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement search service/repository using PostgreSQL full-text search",
            "description": "Create a backend function that executes ranked full-text searches over Songs by title and artist, with pagination.",
            "dependencies": [
              "7.1"
            ],
            "details": "Implementation approach (Flask + SQLAlchemy):\n1) Add a function search_songs(q: str, limit: int = 20, offset: int = 0) -> list[Song], and optionally return a tuple (results, count_estimate) if you decide to include counts later.\n2) Build a tsquery with websearch_to_tsquery('simple', :q) to support AND/OR, quotes, and prefix via trailing '*'.\n3) Query pattern (SQLAlchemy pseudocode):\n   ts_query = func.websearch_to_tsquery('simple', bindparam('q'))\n   rank = func.ts_rank_cd(Song.search_vector, ts_query)\n   stmt = (\n     sa.select(Song, rank.label('rank'))\n       .where(Song.search_vector.op('@@')(ts_query))\n       .order_by(sa.desc(rank), Song.title.asc(), Song.id.asc())\n       .limit(sa.bindparam('limit'))\n       .offset(sa.bindparam('offset'))\n   )\n   Use bound params to prevent SQL injection.\n4) Enforce parameter caps: limit min=1, max=50; offset >= 0.\n5) Consider weighting already encoded in search_vector; rank with ts_rank_cd is sufficient. If you did not weight in the vector, pass weights to ts_rank_cd as needed.\n6) Return a lightweight DTO per song (id, title, artist, and optionally rank) for the API layer.",
            "status": "pending",
            "testStrategy": "Unit tests against a test DB: seed songs with overlapping words across title and artist to verify ranking (title-weighted > artist-weighted). Test: simple term, multi-term AND/OR, quoted phrases, trailing '*' for prefix. Verify pagination and deterministic ordering for ties.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Define API contract and validate request/response for song search",
            "description": "Specify and validate the search endpoint contract, including required query parameter q and pagination parameters, with clear error handling.",
            "dependencies": [
              "7.2"
            ],
            "details": "Implementation approach:\n1) Endpoint: GET /songs/search\n2) Query parameters:\n   - q (required, string, 1..200 chars)\n   - limit (optional, int, default 20, 1..50)\n   - offset (optional, int, default 0, >=0)\n3) Response body (200):\n   {\n     \"results\": [{\"id\": ..., \"title\": \"...\", \"artist\": \"...\", \"rank\": 0.0}],\n     \"limit\": 20,\n     \"offset\": 0,\n     \"count\": null\n   }\n   Note: count can be omitted or null for simplicity; add later if needed.\n4) Errors:\n   - 400 for missing/empty q or invalid params (non-integer limit/offset, out of range)\n5) Validation: Use Marshmallow or Pydantic-like schema for parsing and validating query params; clamp/cap values; trim q; reject queries that are whitespace-only.\n6) Document in OpenAPI/Swagger (path, parameters, responses).",
            "status": "pending",
            "testStrategy": "Contract tests: validate 400 on invalid q, negative offset, excessive limit. Validate schema of 200 response. Include an OpenAPI validation step if available.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implement GET /songs/search endpoint in Flask",
            "description": "Create the Flask route/controller that validates input, invokes the search service, and returns JSON results.",
            "dependencies": [
              "7.3"
            ],
            "details": "Implementation approach:\n1) Add route in the songs blueprint/module: @bp.get('/songs/search').\n2) Parse and validate query params using the schema from 7.3. On validation error, return 400 with message and details.\n3) Call search_songs(q, limit, offset) from 7.2. Map returned rows to JSON objects (id, title, artist, optional rank rounded to 4 decimals).\n4) Return 200 JSON: {results, limit, offset}.\n5) Logging: log query terms and pagination (without PII). Add basic timing metrics to observe performance.\n6) Security/performance safeguards: enforce cap on limit, and short-circuit empty q. No authentication required unless product requires it; if auth is required later, add @jwt_required(optional=True) as needed without altering core logic.",
            "status": "pending",
            "testStrategy": "Integration tests with Flask test client: seed a few songs and hit /songs/search. Verify 200 path returns expected ordering, 400 on invalid input, pagination behavior, and absence of server errors. Optionally test JSON serialization and CORS headers if applicable.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "End-to-end search tests and performance smoke checks",
            "description": "Verify correctness across realistic datasets and ensure the GIN index is used so queries remain fast.",
            "dependencies": [
              "7.4"
            ],
            "details": "Implementation approach:\n1) E2E tests (pytest): spin up a test Postgres with migrations applied. Seed 50100 songs with diverse titles/artists.\n2) Correctness scenarios: search by exact title word, artist name, multi-word queries, quoted phrases, punctuation, case-insensitivity, prefix (provide trailing '*'). Validate that top results include expected songs and ranking is sensible.\n3) Pagination scenarios: limit/offset correctness and stable ordering across pages.\n4) Performance smoke: ensure cold query returns in <150 ms on test hardware and <30 ms warm (adjust thresholds per environment). Use EXPLAIN ANALYZE in a diagnostic test (not part of CI by default) to confirm GIN index usage.\n5) Regression harness: add tests for edge cases (empty results, very long q rejected, high Unicode).",
            "status": "pending",
            "testStrategy": "Run the test suite in CI against a Postgres service. Optionally collect EXPLAIN plans and log them for manual inspection. Use a seeded dataset to assert deterministic outcomes.",
            "parentId": "undefined"
          }
        ]
      },
      {
        "id": 8,
        "title": "Core Song Display",
        "description": "Develop the frontend component for displaying songs with basic chord/lyric formatting.",
        "details": "Create a song display component that formats chords and lyrics. Ensure responsive design and compatibility across devices.",
        "testStrategy": "Test display on different devices and screen sizes. Verify formatting accuracy and responsiveness.",
        "priority": "medium",
        "dependencies": [
          "5",
          "6"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "User Preferences Management",
        "description": "Implement storage and retrieval of user preferences for display settings.",
        "details": "Create API endpoints to save and retrieve user preferences. Update the frontend to allow users to customize their display settings.",
        "testStrategy": "Test preference changes and persistence across sessions. Verify API interactions and data consistency.",
        "priority": "medium",
        "dependencies": [
          "4",
          "5"
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "API Integration for Song Import",
        "description": "Integrate with external APIs (Ultimate Guitar, Songsterr) for song import.",
        "details": "Develop backend services to fetch and import songs from external APIs. Handle API authentication and rate limits.",
        "testStrategy": "Test API integration with mock and live data. Validate imported data against source APIs.",
        "priority": "medium",
        "dependencies": [
          "6",
          "7"
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-09-26T22:55:36.051Z",
      "taskCount": 10,
      "completedCount": 3,
      "tags": [
        "master"
      ],
      "created": "2025-09-26T22:55:40.099Z",
      "description": "Tasks for master context"
    }
  }
}